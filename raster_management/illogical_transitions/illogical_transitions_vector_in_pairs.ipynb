{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illogical transitions in pairs\n",
    "- This script wraps up a batch of vector files located in a folder and creates a series of illogical transition files based on all the possible pairs of the input data.\n",
    "\n",
    "- Inputs\n",
    "    - Path of the folder with the vector files.\n",
    "    - Path of the csv with all the illogical transitions (val1, val2) without headers.\n",
    "    - Column reference name of the vector files for rasterization.\n",
    "    - Rasterization properties: data type, rows, columns...\n",
    "    - Path of the csv file without headers containing or:\n",
    "        - 1 column table with all the accurate names.\n",
    "        - 2 column table with the values and its corresponding names.\n",
    "- Outputs\n",
    "    - Path of the output folder with the final illogical transitions.\n",
    "- Processing\n",
    "    - Read all the vector input files.\n",
    "    - Optional: Dissolve them to make the rest of the process easier.\n",
    "    - Check the input column if it is based on values or text.\n",
    "    - Create the corresponding dictionary for classification.\n",
    "    - Homogenize the reference column with the dictionary.\n",
    "    - Create intermediate vector files.\n",
    "    - Rasterize the reference column.\n",
    "    - Compare all the years in pairs creating the corresponding illogical files.\n",
    "        - Raster files with ID values.\n",
    "        - csv with ID values and pair accumulated values.\n",
    "- Author\n",
    "    - RubÃ©n Crespo Ceballos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.transform import from_origin\n",
    "from osgeo import gdal, ogr, osr\n",
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_if_not_exists(folder_path):\n",
    "    \"\"\"\n",
    "    Create a folder if it doesn't exist.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path of the folder to be created.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder created at: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists at: {folder_path}\")\n",
    "\n",
    "def get_vector_file_list(path):\n",
    "    \"\"\"\n",
    "    Get a list of the vector files inside the folder\n",
    "    Parameters:\n",
    "    - path (str): path of the folder with the resources.\n",
    "\n",
    "    Returns:\n",
    "    - File_list (list). list of the resources.\n",
    "    \"\"\"\n",
    "    File_list = [] #f for f in os.listdir(path) if os.isfile(mypath,f)\n",
    "    for file in os.listdir(path):\n",
    "        # \"anat\" is just to get here necessary ones\n",
    "        if file.endswith(\".shp\"):\n",
    "            if file not in File_list:\n",
    "                File_list.append(os.path.join(path,file))\n",
    "        else:\n",
    "            pass\n",
    "    return File_list\n",
    "\n",
    "def get_raster_file_list(path):\n",
    "    \"\"\"\n",
    "    Get a list of the raster files inside the folder\n",
    "    Parameters:\n",
    "    - path (str): path of the folder with the resources.\n",
    "\n",
    "    Returns:\n",
    "    - File_list (list). list of the resources.\n",
    "    \"\"\"\n",
    "    File_list = [] #f for f in os.listdir(path) if os.isfile(mypath,f)\n",
    "    for file in os.listdir(path):\n",
    "        # \"32628\" is just to get here necessary ones\n",
    "        if file.endswith(\".tif\") or file.endswith(\".tiff\"):\n",
    "            if file not in File_list:\n",
    "                File_list.append(os.path.join(path,file))\n",
    "        else:\n",
    "            pass\n",
    "    return File_list\n",
    "\n",
    "def get_csv_file_list(path):\n",
    "    \"\"\"\n",
    "    Get a list of the csv files inside the folder\n",
    "    Parameters:\n",
    "    - path (str): path of the folder with the resources.\n",
    "\n",
    "    Returns:\n",
    "    - File_list (list). list of the resources.\n",
    "    \"\"\"\n",
    "    File_list = [] #f for f in os.listdir(path) if os.isfile(mypath,f)\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            if file not in File_list:\n",
    "                File_list.append(os.path.join(path,file))\n",
    "        else:\n",
    "            pass\n",
    "    return File_list\n",
    "\n",
    "def update_names_based_on_similarity(unique_names, gdf, column_name, similarity_threshold=0):\n",
    "    \"\"\"\n",
    "    Update names in gdf based on similarity to names in unique list.\n",
    "\n",
    "    Parameters:\n",
    "    - unique_names (list): list of the unique names.\n",
    "    - gdf (GeoDataFrame): GeoDataFrame whose names need to be updated.\n",
    "    - column_name (str): String of the column.\n",
    "    - similarity_threshold (float): Threshold for similarity ratio.\n",
    "\n",
    "    Returns:\n",
    "    - gdf. Updates gdf in place.\n",
    "    \"\"\"\n",
    "    # Add a new column 'valid_text' with None values\n",
    "    gdf['valid_text'] = None\n",
    "\n",
    "    total_elements = len(gdf)  # Get total number of elements\n",
    "\n",
    "    # Iterate through rows of gdf2\n",
    "    for index, row in gdf.iterrows():\n",
    "\n",
    "        # Get the value of the column for the current row\n",
    "        name_gdf = row[column_name]\n",
    "        highest_similarity_ratio = 0\n",
    "        best_matching_name = None\n",
    "        # Iterate through unique names in gdf1\n",
    "        for unique_name in unique_names:\n",
    "            # Calculate similarity ratio between names in gdf2 and gdf1\n",
    "            similarity_ratio = SequenceMatcher(None, unique_name, name_gdf).ratio()\n",
    "            # Update best matching name if similarity ratio is higher\n",
    "            if similarity_ratio > highest_similarity_ratio:\n",
    "                highest_similarity_ratio = similarity_ratio\n",
    "                best_matching_name = unique_name\n",
    "\n",
    "        if highest_similarity_ratio >= similarity_threshold:\n",
    "            # confirmation = input(f\"Similarity found: '{name_gdf2}' -> '{name_gdf1}'Is this okay? (y/n): \").strip().lower()\n",
    "            # if confirmation == \"y\":\n",
    "            # print(f\"{highest_similarity_ratio} for {name_gdf1} to {best_matching_name}\")\n",
    "            gdf.at[index, 'valid_text'] = best_matching_name\n",
    "\n",
    "        print(f\"Processing element {index + 1}/{total_elements}\", end=\"\\r\") # This is to track the process\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def create_identifier_dictionary(list):\n",
    "    \"\"\"\n",
    "    Creates a dictionary out of a list appending a new id to each one of them.\n",
    "\n",
    "    Parameters:\n",
    "    - list (list): list of strings.\n",
    "\n",
    "    Returns:\n",
    "    - value_to_text_dict. dictionary o value: text.\n",
    "    \"\"\"\n",
    "    value_to_text_dict = {value: index + 1 for index, value in enumerate(sorted(list))}\n",
    "    return value_to_text_dict\n",
    "\n",
    "def csv_to_dict(file_path):\n",
    "    \"\"\"\n",
    "    Creates a dictionary out of a csv of two columns excluding the header.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (string): lpath of the file.\n",
    "\n",
    "    Returns:\n",
    "    - result_dict(dict). dictionary o value: text.\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    # Open the CSV file\n",
    "    with open(file_path, mode='r', newline='', encoding='ISO-8859-1') as file: # encoding='ISO-8859-1' encoding='utf-8'\n",
    "        reader = csv.reader(file)\n",
    "        \n",
    "        # Skip the header\n",
    "        # next(reader)\n",
    "        \n",
    "        # Iterate through each row and add to the dictionary\n",
    "        for row in reader:\n",
    "            key = row[1]  # First column as the key\n",
    "            value = row[0]  # Second column as the value\n",
    "            result_dict[float(key)] = value\n",
    "            \n",
    "    return result_dict\n",
    "\n",
    "def csv_to_list(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with one column and transforms it into a list.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (string): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - return(list): List containing the values from the column\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    with open(file_path, mode='r', newline='', encoding='ISO-8859-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if row:  # Ensure the row is not empty\n",
    "                result.append(row[0])\n",
    "    return result\n",
    "\n",
    "def rasterize_geodataframe_by_column(gdf, value_to_index, resolution, nodata_value, data_type, output_path):\n",
    "    \"\"\"\n",
    "    Rasterizes a geodataframe based on the column field.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): GeoDataFrame to be rasterized.\n",
    "    - column_name (str): String of the column name.\n",
    "    - resolution (int): resolution of the raster.\n",
    "    - output_path (str): output of the raster file.\n",
    "\n",
    "    Returns:\n",
    "    - None. Rasterizes the geodataframe.\n",
    "    \"\"\"\n",
    "       \n",
    "    # Get the bounds of the GeoDataFrame\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "    # Calculate the number of pixels in x and y directions\n",
    "    cols = int((xmax - xmin) / resolution)\n",
    "    rows = int((ymax - ymin) / resolution)\n",
    "    # Create a transform for the raster\n",
    "    transform = from_origin(xmin, ymax, resolution, resolution)\n",
    "\n",
    "    # Create an empty array to hold the rasterized values\n",
    "    # rasterized_array = np.zeros((rows, cols), dtype=data_type) # if bigger, change the dtype. This is crucial. # np.uint8\n",
    "    rasterized_array = np.full((rows, cols), nodata_value, dtype=data_type)\n",
    "\n",
    "    total_values = len(value_to_index)\n",
    "\n",
    "    # Rasterize each unique value separately\n",
    "    for idx, (text_value, value) in enumerate(value_to_index.items()):\n",
    "        print(f\"Processing {idx + 1} out of {total_values}\")\n",
    "        mask = gdf['raster_val'] == value\n",
    "        shapes = gdf.loc[mask, 'geometry']\n",
    "        if shapes.empty:\n",
    "            # The value_to_index contains all the possible parameters, but there are some that don't exists in a certain file\n",
    "            continue\n",
    "\n",
    "        temp_raster = features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=(rows, cols),\n",
    "            transform=transform,\n",
    "            all_touched=True, # Esto asegura que si toca la linea del poligono, se genera el pixel\n",
    "            default_value=value,\n",
    "            dtype=data_type, # must be equal to the zeros # np.uint8\n",
    "        )\n",
    "        rasterized_array = np.maximum(rasterized_array, temp_raster)\n",
    "\n",
    "    crs = gdf.crs\n",
    "\n",
    "    # Define the metadata for the raster\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': rows,\n",
    "        'width': cols,\n",
    "        'count': 1,\n",
    "        'dtype': data_type,\n",
    "        'crs': crs, #CRS.from_epsg(32628),\n",
    "        'transform': transform,\n",
    "        'nodata': nodata_value,  # Set the nodata value in the profile metadata\n",
    "        'compress': 'deflate',  # Compression method\n",
    "        'tiled': True,  # Enable tiling\n",
    "        'legend': {str(key): value for key, value in value_to_index.items()}\n",
    "    }\n",
    "\n",
    "    # Write the raster array to a GeoTIFF file\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(rasterized_array, 1)\n",
    "\n",
    "        # Set nodata values in the raster\n",
    "        # rasterized_array[rasterized_array == 0] = nodata_value\n",
    "        # dst.write(rasterized_array, 1)\n",
    "    \n",
    "\n",
    "def gdal_rasterize_from_shapefile(shapefile_path, resolution, nodata_value, data_type, output_path, cols=None, rows=None):\n",
    "    \"\"\"\n",
    "    Rasterizes a GeoDataFrame using GDAL directly.\n",
    "\n",
    "    Parameters:\n",
    "    - shapefile_path (string): path of the vector file.\n",
    "    - resolution (int or float): Resolution of the raster (pixel size).\n",
    "    - nodata_value: The value to use for no-data pixels.\n",
    "    - data_type: Data type for the output raster (e.g., gdal.GDT_Float32).\n",
    "    - output_path (str): Path to save the output raster.\n",
    "    - cols (int, optional): Number of columns in the output raster.\n",
    "    - rows (int, optional): Number of rows in the output raster.\n",
    "\n",
    "    Returns:\n",
    "    - None. The function writes the raster to the specified output path.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the Shapefile using OGR\n",
    "    shapefile = ogr.Open(shapefile_path)\n",
    "    layer = shapefile.GetLayer()\n",
    "\n",
    "    # Get the bounds of the Shapefile (same as GeoDataFrame's total_bounds)\n",
    "    xmin, xmax, ymin, ymax = layer.GetExtent()\n",
    "\n",
    "    # If cols and rows are not provided, calculate them based on resolution\n",
    "    if cols is None or rows is None:\n",
    "        cols = int((xmax - xmin) / resolution)\n",
    "        rows = int((ymax - ymin) / resolution)\n",
    "\n",
    "    # Create a new raster dataset\n",
    "    raster_ds = gdal.GetDriverByName('GTiff').Create(\n",
    "        output_path, cols, rows, 1, data_type,\n",
    "        options=['COMPRESS=DEFLATE', 'TILED=YES']\n",
    "    )\n",
    "\n",
    "    # Set the geotransform (affine transform for the raster)\n",
    "    geotransform = (xmin, resolution, 0, ymax, 0, -resolution)\n",
    "    raster_ds.SetGeoTransform(geotransform)\n",
    "\n",
    "    # Set the CRS (coordinate reference system) from the Shapefile\n",
    "    srs = layer.GetSpatialRef()\n",
    "    if srs:\n",
    "        raster_ds.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "    # Create the raster band and set no-data value\n",
    "    band = raster_ds.GetRasterBand(1)\n",
    "    band.SetNoDataValue(nodata_value)\n",
    "\n",
    "    # Rasterize the shapefile\n",
    "    gdal.RasterizeLayer(\n",
    "        raster_ds,  # Output raster dataset\n",
    "        [1],        # Raster band to write to\n",
    "        layer,      # Input OGR layer to rasterize\n",
    "        options=['ATTRIBUTE=raster_val', 'ALL_TOUCHED=TRUE']\n",
    "    )\n",
    "\n",
    "    # Flush and close the raster dataset\n",
    "    band.FlushCache()\n",
    "    raster_ds = None  # Close the file and save\n",
    "\n",
    "    # Close the shapefile\n",
    "    shapefile = None\n",
    "\n",
    "    print(f\"Rasterization complete: {output_path}\")\n",
    "\n",
    "def check_same_dimensions(raster_files):\n",
    "    \"\"\"\n",
    "    Check the if the dimensions of all the input rasters have the same dimensions.\n",
    "\n",
    "    Parameters:\n",
    "    - raster_files (list): List of raster files.\n",
    "\n",
    "    Returns:\n",
    "    - dimensions_list (list). The list with all the dimensions.\n",
    "    \"\"\"\n",
    "    dimensions_list = []\n",
    "\n",
    "    # Open the first raster file in the list\n",
    "    for file_path in raster_files[:]:\n",
    "        with rasterio.open(file_path) as src:\n",
    "            shape_dimensions = src.shape\n",
    "            dimensions_list.append(shape_dimensions)\n",
    "\n",
    "    if len(set(dimensions_list)) == 1:\n",
    "        print(f\"All the elements have the same dimensions{dimensions_list[0]}\")\n",
    "        dimensions_list\n",
    "    else:\n",
    "        print(\"The dimensions are note the same\")\n",
    "        return dimensions_list\n",
    "\n",
    "\n",
    "def read_csv_in_pairs(csv_file):\n",
    "    \"\"\"\n",
    "    Reads a two column csv and transforms it into a pair value list.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file (str): path of the csv file.\n",
    "\n",
    "    Returns:\n",
    "    - rule_values_list: list of unique value pairs.\n",
    "    \"\"\"\n",
    "    rule_values_list = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        # next(file)  # Skip the header row\n",
    "        for line in file:\n",
    "            # Split the line into two values based on spaces, and convert them to floats\n",
    "            rule_value_1, rule_value_2 = map(float, line.split(\",\"))\n",
    "            rule_values_list.append((rule_value_1, rule_value_2))\n",
    "    return rule_values_list\n",
    "\n",
    "def generate_random_pairs(paths_list):\n",
    "    \"\"\"\n",
    "    Generates a list of random unique pairs, from the input list.\n",
    "\n",
    "    Parameters:\n",
    "    - paths_list (list): list of paths.\n",
    "\n",
    "    Returns:\n",
    "    - all_pairs: list of unique value pairs.\n",
    "    \"\"\"\n",
    "    # Generate all possible pairs from the raster paths\n",
    "    all_pairs = list(itertools.combinations(paths_list, 2))\n",
    "    # Randomly shuffle the list of pairs\n",
    "    random.shuffle(all_pairs)\n",
    "    return all_pairs\n",
    "\n",
    "\n",
    "def compare_rasters(raster_pair, output, rule_table_path, nodata_value):\n",
    "    \"\"\"\n",
    "    Generates a list of random unique pairs, from the input list.\n",
    "\n",
    "    Parameters:\n",
    "    - raster_pair (list): list of two elements.\n",
    "    - output (path): path of the output file.\n",
    "    - rule_table_path (list): is a list of pairs.\n",
    "\n",
    "    Returns:\n",
    "    - output_loc (str): path out the ourput file. \n",
    "    - comparison_df: dataframe related to the data.\n",
    "    \"\"\"\n",
    "    # Open raster files\n",
    "    ds1 = gdal.Open(raster_pair[0])\n",
    "    ds2 = gdal.Open(raster_pair[1])\n",
    "\n",
    "    if not ds1 or not ds2:\n",
    "        print(\"Error: Unable to open raster files.\")\n",
    "        return\n",
    "    \n",
    "    # Check if both rasters have the same height and width\n",
    "    if ds1.RasterXSize != ds2.RasterXSize or ds1.RasterYSize != ds2.RasterYSize:\n",
    "        print(\"Error: Rasters have different dimensions.\")\n",
    "    \n",
    "    # Get the first raster information\n",
    "    width = ds1.RasterXSize\n",
    "    height = ds1.RasterYSize\n",
    "    geotransform = ds1.GetGeoTransform()\n",
    "    projection = ds1.GetProjection()\n",
    "    \n",
    "    # Read rule table and create a list of pairs with the info\n",
    "    rule_values_list = read_csv_in_pairs(rule_table_path)\n",
    "\n",
    "    # Create output raster\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    year1 = os.path.basename(raster_pair[0]).split('_')[-1].replace(\".tif\",\"\") # Get always the last element\n",
    "    year2 = os.path.basename(raster_pair[1]).split('_')[-1].replace(\".tif\",\"\")\n",
    "    output_filename = f\"{year1}_{year2}_illogical_transitions.tif\" #Customize\n",
    "    output_loc = os.path.join(output, output_filename)\n",
    "\n",
    "    output_ds = driver.Create(output_loc, width, height, 1, gdal.GDT_Int16, options= ['COMPRESS=DEFLATE', 'TILED=YES']) # GDT_Int32\n",
    "    output_ds.GetRasterBand(1).SetNoDataValue(nodata_value)\n",
    "    output_ds.SetGeoTransform(geotransform)\n",
    "    output_ds.SetProjection(projection)\n",
    "\n",
    "    output_array = np.zeros((height, width), dtype=np.int16) # int16\n",
    "\n",
    "    unique_value_dict = {} # pairs : unique_value\n",
    "\n",
    "\n",
    "    # Loop through each pixel and compare values\n",
    "    block_size = 256  # Adjust the block size as needed\n",
    "    for y in range(0, height, block_size):\n",
    "        for x in range(0, width, block_size):\n",
    "            print(f\"Comparing pixels at rows/columns ({x},{y}) from ({width}, {height})\", end='\\r')\n",
    "            block_width = min(block_size, width - x)\n",
    "            block_height = min(block_size, height - y)\n",
    "\n",
    "            block1 = ds1.GetRasterBand(1).ReadAsArray(x, y, block_width, block_height)\n",
    "            block2 = ds2.GetRasterBand(1).ReadAsArray(x, y, block_width, block_height)\n",
    "    \n",
    "            # Check if the pair of values matches any rule pair\n",
    "            correct_value = 0\n",
    "            \n",
    "            rule_values_list = set(rule_values_list) # To speed up the process, don't use list\n",
    "            for i in range(block_height):\n",
    "                for j in range(block_width):\n",
    "                    value1 = block1[i, j]\n",
    "                    value2 = block2[i, j]\n",
    "\n",
    "                    if (value1, value2) in rule_values_list: # CHANGE THIS LATER\n",
    "                        unique_value = unique_value_dict.setdefault((value1, value2), len(unique_value_dict) + 1)\n",
    "                        output_array[y + i, x + j] = unique_value\n",
    "\n",
    "                    else:\n",
    "                        output_array[y + i, x + j] = correct_value\n",
    "\n",
    "    # Write the output\n",
    "    output_ds.GetRasterBand(1).WriteArray(output_array)\n",
    "\n",
    "    # Close datasets\n",
    "    ds1 = None\n",
    "    ds2 = None\n",
    "    output_ds = None\n",
    "\n",
    "    # Create the dataframe\n",
    "    unique_values = list(unique_value_dict.values())\n",
    "    value_pairs = list(unique_value_dict.keys())\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'univalue': unique_values,\n",
    "        f'Val1_{year1}': [pair[0] for pair in value_pairs],\n",
    "        f'Val2_{year2}': [pair[1] for pair in value_pairs]\n",
    "                                })\n",
    "    \n",
    "    # Lets export the csv just in case\n",
    "    comparison_df.to_csv(os.path.join(output, f\"illogical_table_{year1}_{year2}.csv\"), index=False)\n",
    "\n",
    "    return output_loc, comparison_df\n",
    "\n",
    "\n",
    "def vectorize_raster(raster_path, output_path, df):\n",
    "    \"\"\"\n",
    "    Vectorizes an input raster.\n",
    "\n",
    "    Parameters:\n",
    "    - raster_path (str): path of the input raster.\n",
    "    - output_path (path): path of the output file.\n",
    "    - df (dataframe): dataframe related to the input raster.\n",
    "\n",
    "    Returns:\n",
    "    - None. It produces the vector file. \n",
    "    \"\"\"\n",
    "    # Open the raster file\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Read raster data as numpy array\n",
    "        data = src.read(1)\n",
    "        # Get affine transform of the raster\n",
    "        transform = src.transform\n",
    "\n",
    "    # Vectorize the raster data\n",
    "    raster_shapes = features.shapes(data, transform=transform)\n",
    "\n",
    "    # Convert the vectorized shapes into a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame.from_features(\n",
    "        [\n",
    "            {\"geometry\": geo_shape, \"properties\": {\"univalue\": value}}\n",
    "            for geo_shape, value in raster_shapes\n",
    "        ],\n",
    "        crs=src.crs\n",
    "    )\n",
    "\n",
    "    # Merge the dataframe with the GeoDataFrame\n",
    "    merged_gdf = gdf.merge(df, on='univalue')\n",
    "    # Dissolve based on a column value\n",
    "    dissolved_gdf = merged_gdf.dissolve(by='univalue')\n",
    "\n",
    "    # Save the merged GeoDataFrame as a new shapefile\n",
    "    filename = os.path.join(output_path, os.path.basename(raster_path).split('.')[0])\n",
    "    dissolved_gdf.to_file(f'{filename}.shp', driver='ESRI Shapefile')\n",
    "    return\n",
    "\n",
    "def add_name_columns_to_dataframe(df, column_name, names_dictionary):\n",
    "    \"\"\"\n",
    "    Adds the input name list into the  an input raster.\n",
    "\n",
    "    Parameters:\n",
    "    - df (dataframe): dataframe related to the input raster.\n",
    "    - column_name (str): name of the column that is appeended to the df.\n",
    "    - names_dictionary (dict): dict of the names that we want to append.\n",
    "\n",
    "    Returns:\n",
    "    - df (dataframe). It produces the updated dataframe with the names. \n",
    "    \"\"\"\n",
    "    reversed_dict = {v: k for k, v in names_dictionary.items()} # Reverse it to match the values / value: text\n",
    "    count = 1\n",
    "    for column in df.columns:\n",
    "        if column.startswith(f'Val{count}'):\n",
    "            #Creates a new column witht the column_name matching the value of the value.\n",
    "            df[column_name + str(count)] = df[column].map(reversed_dict)\n",
    "            count += 1\n",
    "    return df\n",
    "\n",
    "def dissolve_geodataframe(gdf, column):\n",
    "    \"\"\"\n",
    "    Dissolves a GeoDataFrame based on unique values of a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): Input GeoDataFrame to be dissolved.\n",
    "    column (str): Column name based on which to dissolve the GeoDataFrame.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: The dissolved GeoDataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Initial number of geometries: {len(gdf)}\")\n",
    "    \n",
    "    # Perform the dissolve operation\n",
    "    dissolved_gdf = gdf.dissolve(by=column)\n",
    "    \n",
    "    print(f\"Final number of geometries after dissolve: {len(dissolved_gdf)}\")\n",
    "    \n",
    "    return dissolved_gdf\n",
    "\n",
    "def map_gdf_based_on_column_type(gdf, column_name, names_dictionary, names_list):\n",
    "    \"\"\"\n",
    "    Maps values of a column in a GeoDataFrame (gdf) to unique identifiers based on the data type of the column.\n",
    "    \n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): The input GeoDataFrame.\n",
    "    column_name (str): The name of the column to be mapped.\n",
    "    names_dictionary (dict): A dictionary where keys are valid text and values are unique raster values.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: The modified GeoDataFrame with a new column 'raster_val' representing unique identifiers.\n",
    "    \"\"\"\n",
    "    if gdf[column_name].dtype == object:\n",
    "        print(f\"The column '{column_name}' contains strings.\")\n",
    "        gdf = update_names_based_on_similarity(names_list, gdf, column_name, similarity_threshold=0.5)\n",
    "        print(\"names updated\")\n",
    "        # Add a new column to the GeoDataFrame containing the unique identifiers\n",
    "        gdf['raster_val'] = gdf[\"valid_text\"].map(names_dictionary)\n",
    "    else:\n",
    "        print(f\"The column '{column_name}' does not contain strings.\")\n",
    "        # Get unique values/strings from the specified column, they are always sorted.\n",
    "        unique_values = sorted(gdf[column_name].unique())\n",
    "        # Create a dictionary one to one\n",
    "        value_to_index = {value: value for value in unique_values}\n",
    "        gdf['raster_val'] = gdf[column_name].map(value_to_index)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: Y:\\z_resources\\ruben\\ladncover_test\\output_files\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Specify all the inputs\"\"\"\n",
    "# Path for the vector inputs\n",
    "input_path = r\"Y:\\z_resources\\im-nca-senegal\\v2_shp_occsol_anat\\23-12-22\\shp_occsol_anat\\testing\"\n",
    "\n",
    "# Path for the output illogical files\n",
    "output_path = input_path + r\"\\output_path\"\n",
    "\n",
    "# Path of the illogical rules csv\n",
    "rule_table_path = r\"Y:\\z_resources\\im-nca-senegal\\v2_shp_occsol_anat\\23-12-22\\shp_occsol_anat\\illogical_transitions.csv\"\n",
    "\n",
    "create_folder_if_not_exists(output_path)\n",
    "\n",
    "# Get the original vector files\n",
    "vector_file_list = get_vector_file_list(input_path)\n",
    "\n",
    "\"\"\"We have here two situations we have to develop\"\"\"\n",
    "\n",
    "# If we have only strings with no values so we append a created value.\n",
    "names_list_path = r\"Y:\\z_resources\\im-nca-senegal\\v2_shp_occsol_anat\\23-12-22\\shp_occsol_anat\\testing\\names_list.csv\"\n",
    "names_list = csv_to_list(names_list_path)\n",
    "names_dictionary = create_identifier_dictionary(names_list) # The output will always be number: text \n",
    "\n",
    "# If we have both strings and values\n",
    "names_dictionary_path = r\"Y:\\z_resources\\ruben\\landcover_vector_files_copy\\names_dictionary.csv\" #It has headers\n",
    "names_dictionary = csv_to_dict(names_dictionary_path) # {Code: label}\n",
    "names_list = list(names_dictionary.values())\n",
    "\n",
    "vector_file_list = get_vector_file_list(input_path)\n",
    "\n",
    "\"\"\"For rasterization\"\"\"\n",
    "# Specify the column of the vector file\n",
    "column_name = 'leyenda'\n",
    "# Define the resolution of your raster.\n",
    "resolution = 30  # in meters\n",
    "# Define the nodata value of your raster.\n",
    "nodata_value = 0\n",
    "\n",
    "# Define the data type of the raster.\n",
    "data_type = gdal.GDT_UInt16\n",
    "\"\"\"\n",
    "gdal.GDT_Byte,\n",
    "gdal.GDT_Int16,\n",
    "gdal.GDT_UInt16,\n",
    "gdal.GDT_Int32,\n",
    "gdal.GDT_UInt32,\n",
    "gdal.GDT_Float32,\n",
    "gdal.GDT_Float64\n",
    "\"\"\"\n",
    "\n",
    "# Define the rows and columns for the rasterization (All the files must have the same dimensions). You can take as reference any on the inputs\n",
    "rows = 9999\n",
    "columns = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OPTIONAL: For very dense vector files. We are going to dissolve it based on the designed column, and  Optimise vector files to the fullest\"\"\"\n",
    "dissolved_files_path = input_path + r\"\\dissolved_files\"\n",
    "create_folder_if_not_exists(dissolved_files_path)\n",
    "\n",
    "for file in vector_file_list[:]:\n",
    "    gdf = gpd.read_file(file)\n",
    "    print(\"gdf opened\")\n",
    "    gdf = dissolve_geodataframe(gdf, column_name)\n",
    "    gdf.to_file(os.path.join(dissolved_files_path, os.path.basename(file).replace(\".shp\", \"_optimized.shp\")) , driver='ESRI Shapefile')\n",
    "\n",
    "# We specify the next input\n",
    "vector_file_list = get_vector_file_list(dissolved_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the \"raster_val\" for rasterization according to the content of the columnn\"\"\"\n",
    "optimized_vector_files_path = input_path + r\"\\optimized_vector_files\"\n",
    "create_folder_if_not_exists(optimized_vector_files_path)\n",
    "\n",
    "for file in vector_file_list[:]:\n",
    "    gdf = gpd.read_file(file)\n",
    "    print(f\"gdf {os.path.basename(file)} opened\")\n",
    "    if gdf[column_name].dtype == object:\n",
    "        print(f\"The column '{column_name}' contains strings.\")\n",
    "        gdf = update_names_based_on_similarity(names_list, gdf, column_name, similarity_threshold=0.3)\n",
    "        print(\"names updated\")\n",
    "        # Add a new column to the GeoDataFrame containing the unique identifiers\n",
    "        gdf['raster_val'] = gdf[\"valid_text\"].map(names_dictionary)\n",
    "        \n",
    "    else:\n",
    "        print(f\"The column '{column_name}' contains values.\")\n",
    "        # Get unique values/strings from the specified column, they are always sorted.\n",
    "        unique_values = sorted(gdf[column_name].unique())\n",
    "        # Create a dictionary one to one\n",
    "        value_to_index = {value: value for value in unique_values}\n",
    "        gdf['raster_val'] = gdf[column_name].map(value_to_index)\n",
    "    \n",
    "    # Opening and saving the file takes a lot of time\n",
    "    gdf.to_file(os.path.join(optimized_vector_files_path, os.path.basename(file).replace(\".shp\", \"_optimized.shp\")) , driver='ESRI Shapefile')\n",
    "    \n",
    "# Read the new imputs\n",
    "vector_file_list = get_vector_file_list(optimized_vector_files_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Transform the vector files and convert them into rasters\"\"\"\n",
    "rasterized_files_path = input_path + r\"\\rasterized_files_path\"\n",
    "create_folder_if_not_exists(rasterized_files_path)\n",
    "\n",
    "for file in vector_file_list[:]:\n",
    "    output_path_file = os.path.join(rasterized_files_path, os.path.basename(file).replace(\".shp\", \".tif\"))\n",
    "\n",
    "    # gdf = gpd.read_file(file)\n",
    "    print(f\"{os.path.basename(file)} opened\")\n",
    "    # Prepare the dict to raster based on the column\n",
    "    # gdf = map_gdf_based_on_column_type(gdf, column_name, names_dictionary, names_list)\n",
    "    \n",
    "    print(\"Rasterizing: \" , output_path_file)\n",
    "    \n",
    "    # Slow method (I won't delete it jet)\n",
    "    # rasterize_geodataframe_by_column(gdf, names_dictionary, resolution, nodata_value, data_type, output_path_file)\n",
    "    \n",
    "    # Fast method\n",
    "    gdal_rasterize_from_shapefile(file, resolution, nodata_value, data_type, output_path_file, cols=None, rows=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the elements have the same dimensions(129, 262)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check the dimensions of the rasters\"\"\"\n",
    "raster_list = get_raster_file_list(rasterized_files_path)\n",
    "check_same_dimensions(raster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: Y:\\z_resources\\ruben\\ladncover_test\\illogical_files\n",
      "Comparing pixels at rows/columns (256,0) from (262, 129)\r"
     ]
    }
   ],
   "source": [
    "\"\"\"Create the illogical transitions 1 to 1 and vectorize it\"\"\"\n",
    "illocical_raster_nodata_value = 0\n",
    "\n",
    "raster_list = get_raster_file_list(rasterized_files_path)\n",
    "all_pairs_path_list = generate_random_pairs(raster_list)\n",
    "\n",
    "for raster_pair in all_pairs_path_list[:]:\n",
    "    illogical_raster_path, illogical_df = compare_rasters(raster_pair, output_path, rule_table_path, illocical_raster_nodata_value)\n",
    "    illogical_df = add_name_columns_to_dataframe(illogical_df, column_name, names_dictionary)\n",
    "    # Comment the next part if you don't want to vectorize it directly\n",
    "    vectorize_raster(illogical_raster_path, output_path, illogical_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If the vectorization is independent\"\"\"\n",
    "Illogical_raster_list = get_raster_file_list(output_path)\n",
    "illogical_csvs = get_csv_file_list(output_path)\n",
    "\n",
    "for illogical_raster_path, csv_file in zip(Illogical_raster_list, illogical_csvs):\n",
    "    illogical_df = pd.read_csv(csv_file)\n",
    "    illogical_df = add_name_columns_to_dataframe(illogical_df, column_name, names_dictionary)\n",
    "    vectorize_raster(illogical_raster_path, output_path, illogical_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_forge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
